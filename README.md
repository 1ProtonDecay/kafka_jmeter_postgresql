Развернуть у себя kafka (можно локально, можно в докере), запустить и создать топик. С ним будет вестись дальнейшая работа в рамках пунктов 1.2 и 1.3.
Для выполнения задания понадобится вручную поднять Kafka и Zookeeper. Инструкции в интернете в помощь. 
Чтобы просмотреть очередь сообщений в кафке, можно воспользоваться Kafka Tool. 

Развернуть инстанс PostgreSQL, создать в нем произвольную таблицу со столбцами msgId, head, timeRq.

Задание №1.2
Задание требует выполненного пункта №1.1, т.к. в нем потребуется нагрузить кафку, которую мы ранее настраивали. Желательно использовать инструмент jMeter (опционально допускается любой другой инструмент НТ), чтобы написать тестовый скрипт и сценарий нагрузки: 

1.	Скрипт должен отправлять в кафку сообщение, каждый раз используя случайный msg_id в теле запроса. У каждого 10 сообщения параметр head должен иметь значение false.
      Пример сообщения в топик Kafka: { "msg_id": "1234567890", "head": true, "method": "POST", "uri": "/post-message" }
2.	Необходимо также реализовать сценарий нагрузки:
      a.	Нагрузку подавать ступенями по 5 минут;
      b.	Всего 4 ступени;
      c.	На первой ступени нагрузки подаем запросы со скоростью 0,5 оп/с. На второй ступени 1 оп/с, на третьей – 2 оп/с, на четвертой – 3 оп/с.
      Задание №1.3
      Разработать заглушку на Java (Spring), которая обеспечивает обработку поступащих kafka-запросов и запись данных в подготовленную в п.1 БД.
1.	Заглушка постоянно в ходе своей работы слушает топик kafka, созданный в п.1.1
2.	Получив сообщение, заглушка должна достать из тела запроса msg_id и head, и на их основе сформировать запись в БД, вписав их данные, соответственно в столбцы msgId, head. В столбец timeRq записать время (в формате UNIX) когда заглушка вычитала сообщение из топика;
3.	Заглушка выводит в лог каждый поступающий запрос и о созданной записи в БД

Чтобы просмотреть очередь сообщений в кафке, можно воспользоваться Kafka Tool. Для контроля работы БД можно воспользоваться любым клиентом, например, DBeaver.